{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YKhg3oXivDEq"
      },
      "outputs": [],
      "source": [
        "#Q1.What is Simple Linear Regression?\n",
        "#Ans: SLR method used to predict a continuous dependent variable (Y) using one independent variable (X) by fitting a straight line of best fit.\n",
        "#equation:\n",
        "#y=mx+c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2.What are the key assumptions of Simple Linear Regression?\n",
        "#Ans:The line between X and Y should be straight.Each data point should not depend on another.The spread of errors should be the same everywhere."
      ],
      "metadata": {
        "id": "cKsAXQuxve2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3.What does the coefficient m represent in the equation Y=mX+c?\n",
        "#here in equation m represent the slope."
      ],
      "metadata": {
        "id": "kyAQ_Tf1wRW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4.What does the intercept c represent in the equation Y=mX+c?\n",
        "#c is the intercept.it is the point where the line crosses the Y-axis."
      ],
      "metadata": {
        "id": "j6o47t48wRUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5.How do we calculate the slope m in Simple Linear Regression?\n",
        "#m=summition of (x-xbar)(y-ybar)/(x-xbar)square"
      ],
      "metadata": {
        "id": "uj3VZ3sjwRRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q6.What is the purpose of the least squares method in Simple Linear Regression?\n",
        "#The least squares method finds the best-fitting line by minimizing the:Sum of Squared Errors (SSE)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U-h0TmfbxTvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q7.How is the coefficient of determination (R²) interpreted?\n",
        "#R² measures how well the model explains variability in Y."
      ],
      "metadata": {
        "id": "0BSOP_iKxrUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q8.What is Multiple Linear Regression?\n",
        "#Multiple Linear Regression predicts Y using two or more independent variables.\n",
        "#equation:Y=b0​+b1​X1​+b2​X2​+...+bn​Xn​"
      ],
      "metadata": {
        "id": "Hh3MvdwkxrRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q9.What is the main difference between Simple and Multiple Linear Regression?\n",
        "#SLR has one independent variable.2.equation is :y=mx+c\n",
        "#MLR has two or more independent variables 3.equation is:Y=b0​+b1​X1​+b2​X2​+...+bn​Xn​\n"
      ],
      "metadata": {
        "id": "7a8-Vo5cyMa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q10.What are the key assumptions of Multiple Linear Regression?\n",
        "#Linearity\n",
        "#Independence of errors\n",
        "#Homoscedasticity (constant variance)\n",
        "#Normality of residuals\n",
        "#independent variables should not be highly correlated\n",
        "#No influential outliers"
      ],
      "metadata": {
        "id": "d1N_xjNLysQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model\n",
        "#Heteroscedasticity means the variance of the errors is not constant (errors spread out unevenly).\n",
        "#Makes coefficients less reliable.p-values become incorrect.Model predictions become less accurate"
      ],
      "metadata": {
        "id": "-MhNfLGxyMX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q12.How can you improve a Multiple Linear Regression model with high multicollinearity\n",
        "#Removing one of the highly correlated variables.Combining variables (e.g., using averages)\n",
        ""
      ],
      "metadata": {
        "id": "5lMhlsSx1tAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q13.What are some common techniques for transforming categorical variables for use in regression models\n",
        "#One-hot encoding (dummy variables)\n",
        "#Label encoding (for ordinal data)\n",
        "#Target encoding (replaces category with mean of target)\n",
        "#Binary encoding\n",
        "#Ordinal encoding (if categories have order)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CGFs6I8k2cgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Q14.What is the role of interaction terms in Multiple Linear Regression\n",
        " #Interaction terms show how two variables together affect Y\n",
        ""
      ],
      "metadata": {
        "id": "09rmm3M_3L_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q15.How can the interpretation of intercept differ between Simple and Multiple Linear Regression\n",
        "#Simple: The intercept is the value of Y when X = 0.\n",
        "#Multiple: The intercept is the value of Y when all X’s = 0.\n",
        ""
      ],
      "metadata": {
        "id": "haFUzMhT3L8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q16.What is the significance of the slope in regression analysis, and how does it affect predictions\n",
        "'''slope tells how much Y changes when X increases by 1 unit.\n",
        "Positive slope → Y increases\n",
        "Negative slope → Y decreases\n",
        "Higher slope → stronger effect on prediction'''\n"
      ],
      "metadata": {
        "id": "fqnqlhKW3L5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q18. What are the limitations of using R² as a sole measure of model performance\n",
        "'''  R² always increases when adding more variables\n",
        "a positive slope tells when x increase ,y also increase.\n",
        "nagative slope tell when x increases y decreases  '''\n",
        ""
      ],
      "metadata": {
        "id": "UkDVNrpG3eoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q19.How would you interpret a large standard error for a regression coefficient\n",
        "'''A large standard error means we are not confident about the value of the coefficient. It could be wrong or unstable.'''\n",
        ""
      ],
      "metadata": {
        "id": "Ew4iijTa3elP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yn4oo2fP3eiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q20.How can heteroscedasticity be identified in residual plots, and why is it important to address it\n",
        " ''' The intercept tells you the value of the dependent variable (Y) when all independent variables (X’s) are equal to zero.\n",
        " it is useful because it gives the baseline value.helps to interpret the module.make prediction possible sometimes its meaningful sometimes not.  '''"
      ],
      "metadata": {
        "id": "KHFHGUcy5mDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q21.What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²\n",
        "'''The model looks good at high R² .adjusted R² drops because many predictors are not actually helping.\n",
        "R² always increases when you add more variables.R² increases only if the new variable improves the model'''"
      ],
      "metadata": {
        "id": "P_K_ihBM5mAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Q22.Why is it important to scale variables in Multiple Linear Regression\n",
        " '''Scaling makes all variables equal in size, so the model learns fairly, faster, and more accurately.'''"
      ],
      "metadata": {
        "id": "x4UouIwM5l-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q23.what is polynomisl regression?\n",
        "'''Polynomial regression fits a curved line instead of a straight line by adding powers of X to the model.'''\n",
        " #equation: Y=b0​+b1​X+b2​X2+b3​X3"
      ],
      "metadata": {
        "id": "Sr5WNM2FCKCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q24.How does polynomial regression differ from linear regression\n",
        "'''Linear Regression:fits a straight line.simple relationship between x and is linear.eqn is :Y=b0​+b1​X\n",
        "polynomial regression:Fits a curved line.Relationship between X and Y is non-linear.Adds powers of X  .eqn is:Y=b0​+b1​X+b2​X2+b3​X3+…......bnXn '''"
      ],
      "metadata": {
        "id": "nkK72FU25l7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q25.When is polynomial regression used\n",
        " ''' Polynomial regression is used when the relationship between the independent variable (X) and the dependent variable (Y) is non-linear, meaning a\n",
        " straight line cannot describe the pattern in the data.\n",
        " Polynomial regression is used when the data is curved and a straight line is not good enough."
      ],
      "metadata": {
        "id": "QK3jwteJCWZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Q26.What is the general equation for polynomial regression\n",
        " #Y=b0​+b1​X+b2​X2+b3​X3+…......bnXn"
      ],
      "metadata": {
        "id": "GhRNnjPb5l4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q27.Can polynomial regression be applied to multiple variables\n",
        " #yes polynomial regression be applied to multiple variales."
      ],
      "metadata": {
        "id": "d1RBN_1j5l1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q28.What are the limitations of polynomial regression\n",
        "'''High risk of overfitting\n",
        "Poor performance outside the data range (extrapolation)\n",
        "Sensitive to outliers.\n",
        "Not good for very large datasets'''\n",
        ""
      ],
      "metadata": {
        "id": "8wcb3jKa5tNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q29.What methods can be used to evaluate model fit when selecting the degree of a polynomial\n",
        "#Use cross-validation, adjusted R², AIC/BIC, and test error to choose the best polynomial degree while avoiding overfitting.\n",
        ""
      ],
      "metadata": {
        "id": "ENwEzvuT5tKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q30.Why is visualization important in polynomial regression\n",
        " #Visualization is very important in polynomial regression because it helps you clearly see whether the model is fitting the data correctly."
      ],
      "metadata": {
        "id": "rLbF0pzN5tIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q31.How is polynomial regression implemented in Python\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "y = np.array([3, 6, 10, 15, 21])\n",
        "\n",
        "# Create model with degree 2 polynomial\n",
        "model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
        "\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "print(\"Predictions:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjqPzmQ05tE5",
        "outputId": "4d0d54b3-4265-4556-ce84-86ede60d1b63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [ 3.  6. 10. 15. 21.]\n"
          ]
        }
      ]
    }
  ]
}